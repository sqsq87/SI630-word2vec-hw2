{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('trained_vector.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04774104,  0.01113729, -0.0854168 , -0.02429663, -0.00778219,\n",
       "        0.05570809,  0.04408854, -0.05375911, -0.09509112, -0.04852701,\n",
       "       -0.01797679, -0.0983202 , -0.00569021,  0.07048442,  0.08463594,\n",
       "       -0.05371277,  0.09819099, -0.09880042, -0.03294989,  0.05785162,\n",
       "       -0.08029769, -0.01153355, -0.02386614,  0.06651969,  0.04239244,\n",
       "       -0.02899984, -0.09507273,  0.0387025 , -0.01575761,  0.07166989,\n",
       "        0.01501471,  0.08801247,  0.0760511 , -0.00837099, -0.09653798,\n",
       "       -0.08626907, -0.0358784 ,  0.01846038,  0.02201049,  0.0024855 ,\n",
       "       -0.07104871,  0.07536174,  0.04764704, -0.02533592,  0.06573728,\n",
       "       -0.0819521 , -0.08719935,  0.00117939,  0.08668534, -0.07020762],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7feb170436d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('essays', 0.8325610160827637),\n",
       " ('articles', 0.8254350423812866),\n",
       " ('novellas', 0.7723618745803833),\n",
       " ('magazines', 0.7717729806900024),\n",
       " ('monographs', 0.76274573802948),\n",
       " ('illustrating', 0.7334399819374084),\n",
       " ('biographies', 0.7303065061569214),\n",
       " ('journals', 0.7293117046356201),\n",
       " ('pages', 0.7265263199806213),\n",
       " ('columns', 0.7254587411880493)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘book’, the qualitatively most similar words are mostly the nouns with the semantic meaning ‘things can be read’ like essays, articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('October', 0.8920010328292847),\n",
       " ('December', 0.8778380155563354),\n",
       " ('February', 0.8765127062797546),\n",
       " ('August', 0.8728427886962891),\n",
       " ('November', 0.8700879812240601),\n",
       " ('March', 0.8650733232498169),\n",
       " ('June', 0.8603971004486084),\n",
       " ('May', 0.8477078676223755),\n",
       " ('September', 0.8467978239059448),\n",
       " ('July', 0.839765191078186)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"April\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘April’, the qualitatively most similar words are mostly the nouns indicating month like October."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('softball', 0.8399666547775269),\n",
       " ('football', 0.8360031843185425),\n",
       " ('soccer', 0.8227754831314087),\n",
       " ('volleyball', 0.8048578500747681),\n",
       " ('baseball', 0.8044962882995605),\n",
       " ('lacrosse', 0.7955363988876343),\n",
       " ('hockey', 0.7667567133903503),\n",
       " ('Goodenbour', 0.7493417263031006),\n",
       " ('tennis', 0.741902768611908),\n",
       " ('sledge', 0.7320674061775208)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"basketball\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘basketball’, the qualitatively most similar words are mostly the nouns indicating sports items like softball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('She', 0.7889261245727539),\n",
       " ('Daccord', 0.6885871291160583),\n",
       " ('Lambertsen', 0.6511487364768982),\n",
       " ('Hailston', 0.6508619785308838),\n",
       " ('Galbally', 0.6429628133773804),\n",
       " ('Pepín', 0.6400373578071594),\n",
       " ('Romell', 0.6359394788742065),\n",
       " ('Moncewicz', 0.6355791091918945),\n",
       " ('Mauborgne', 0.6326525211334229),\n",
       " ('Dário', 0.6298860907554626)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"He\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘He’, the qualitatively most similar words are she and other person names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('30th', 0.8240333199501038),\n",
       " ('64th', 0.8238258361816406),\n",
       " ('23rd', 0.8140838146209717),\n",
       " ('33rd', 0.8038157820701599),\n",
       " ('9th', 0.8005726337432861),\n",
       " ('10th', 0.7996435761451721),\n",
       " ('116th', 0.7987253069877625),\n",
       " ('59th', 0.7891724705696106),\n",
       " ('60th', 0.7865711450576782),\n",
       " ('36th', 0.7852972149848938)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"25th\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘25th’, the qualitatively most similar words are all ordinal numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1962', 0.8537935018539429),\n",
       " ('1951', 0.8409759998321533),\n",
       " ('1950', 0.8306080102920532),\n",
       " ('1955', 0.8281768560409546),\n",
       " ('1949', 0.8229819536209106),\n",
       " ('1934', 0.8175702691078186),\n",
       " ('1933', 0.8130149245262146),\n",
       " ('1946', 0.8127145767211914),\n",
       " ('1961', 0.8122072219848633),\n",
       " ('1959', 0.8111141324043274)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"1967\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘1967’, the qualitatively most similar words are all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('physics', 0.8251581192016602),\n",
       " ('sociology', 0.8141902685165405),\n",
       " ('medicine', 0.8090916872024536),\n",
       " ('zoology', 0.7975834608078003),\n",
       " ('chemistry', 0.7947500348091125),\n",
       " ('economics', 0.7866847515106201),\n",
       " ('geography', 0.7846213579177856),\n",
       " ('botany', 0.7817147970199585),\n",
       " ('engineering', 0.7719976902008057),\n",
       " ('divinity', 0.7719128131866455)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"mathematics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘mathematics’, the qualitatively most similar words are mostly subjects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('From', 0.7463487386703491),\n",
       " ('Until', 0.6833612322807312),\n",
       " ('By', 0.6592501401901245),\n",
       " ('Excavations', 0.634077787399292),\n",
       " ('Obergruppenführer', 0.6191043853759766),\n",
       " ('Appointed', 0.617178201675415),\n",
       " ('Starting', 0.6139140129089355),\n",
       " ('Saydam', 0.6130807399749756),\n",
       " ('Participated', 0.6110838055610657),\n",
       " ('Düren', 0.6091176867485046)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"Between\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘Between’, the first three qualitatively most similar words are prepositions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Czechoslovakia', 0.8479709029197693),\n",
       " ('Croatia', 0.7815450429916382),\n",
       " ('Latvia', 0.7672635912895203),\n",
       " ('Switzerland', 0.7577182054519653),\n",
       " ('Yugoslavia', 0.7551692128181458),\n",
       " ('Ukraine', 0.7487151026725769),\n",
       " ('Slovenia', 0.7282400131225586),\n",
       " ('Morocco', 0.7266643047332764),\n",
       " ('Moldova', 0.7254005074501038),\n",
       " ('Serbia', 0.7202527523040771)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"Finland\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word ‘Finland’, the qualitatively most similar words are other countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hockenheimring', 0.7922357320785522),\n",
       " ('criterium', 0.7663637399673462),\n",
       " ('Nurburgring', 0.7603985071182251),\n",
       " ('eights', 0.7548940181732178),\n",
       " ('10m', 0.750497579574585),\n",
       " ('T37', 0.7494640946388245),\n",
       " ('placings', 0.7486727237701416),\n",
       " ('Alm', 0.7444251775741577),\n",
       " ('hoop', 0.743412971496582),\n",
       " ('relays', 0.7425753474235535)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"pewter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rare word ‘Pewter’, the qualitatively most similar words are not similar to it since the frequency of it is too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man','woman','king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Princess'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('boy','girl','Prince')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prince-boy+girl=princess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actress'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('boy','girl','actor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actor-boy+girl=actress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fast'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('snail','rabbit','slow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slow-snail+rabbit=fast. Rabbit is fast, snail is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('father','mother','man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "man-father+mother=woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'educator'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('sing','teach','singer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "singer-sing+teach=educator. People who sing well is a singer. People who teach well is educator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('winter','summer','December')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "December-winter+summer=June. December is the beginning of winter and June is the beginning of summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
